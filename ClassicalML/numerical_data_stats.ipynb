{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HYn5jBq2_Onh"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2023 Google LLC. Double-click for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25T2QAXLJPso"
      },
      "source": [
        "# Colabs\n",
        "\n",
        "Machine Learning Crash Course uses Colaboratories (Colabs) for all programming exercises. Colab is Google's implementation of [Jupyter Notebook](https://jupyter.org/). For more information about Colabs and how to use them, go to [Welcome to Colaboratory](https://research.google.com/colaboratory).\n",
        "\n",
        "# Numerical data: Statistics on a dataset\n",
        "\n",
        "This Colab programming exercise (first of two) is part of the Machine Learning Crash Course module [Working with numerical data](https://developers.google.com/machine-learning/crash-course/numerical-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiy_IL3AsWkA"
      },
      "source": [
        "## What to expect\n",
        "\n",
        "In the section, [First steps with numerical data](https://developers.google.com/machine-learning/crash-course/numerical-data/first-steps), you learned how to do the following:\n",
        "- Visualize your data in plots or graphs.\n",
        "- Evaluate potential features and labels mathematically.\n",
        "- Find [**outliers**](https://developers.google.com/machine-learning/glossary/#outliers) in the dataset.\n",
        "\n",
        "This exercise takes you through the process of finding columns that contain blatant outliers, which you can then decide to keep in or delete from the dataset."
      ]
    },
    {
      "metadata": {
        "id": "XfnQEaePhztH"
      },
      "cell_type": "code",
      "source": [
        "# @title Setup - Install relevant modules\n",
        "\n",
        "!pip install pandas~=2.2.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyGvT2U4QWmA"
      },
      "outputs": [],
      "source": [
        "# @title Setup - Import relevant modules\n",
        "\n",
        "# The following code imports relevant modules that\n",
        "# allow you to run the colab.\n",
        "# If you encounter technical issues running some of the code sections\n",
        "# that follow, try running this section again.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# The following lines adjust the granularity of reporting.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n-qYeaU9QgIA"
      },
      "outputs": [],
      "source": [
        "#@title Import the dataset\n",
        "\n",
        "# The following code imports the dataset that is used in the colab.\n",
        "\n",
        "training_df = pd.read_csv(filepath_or_buffer=\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CfNPW4GRf09"
      },
      "source": [
        "## Get basic statistics\n",
        "\n",
        "In the following code section, the DataFrame `describe` method returns basic statistics on all the columns in the dataset, such as:\n",
        "\n",
        "* `count` is the number of populated elements in this column. Ideally, every column contains the same value for `count`, but that's not always the case.\n",
        "* `mean` is the traditional average of values in that column. We recommend comparing the `mean` to the median for each column. The **median** is the 50% row of the table.\n",
        "* `std` is the standard deviation of the values in this column.\n",
        "* `min`, `25%`, `50%`, `75%`, and `max` indicate values in the 0, 25, 50, 75, and 100th percentiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faMaLr_4QgzP"
      },
      "outputs": [],
      "source": [
        "# Get statistics on the dataset.\n",
        "\n",
        "# The following code returns basic statistics about the data in the dataframe.\n",
        "\n",
        "training_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkkok1t-Rw1l"
      },
      "source": [
        "### Task: Identify possible outliers\n",
        "\n",
        "Based on the preceding statisics, do you see any columns that might contain outliers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzt1ZVNhvSUM"
      },
      "outputs": [],
      "source": [
        "# @title Solution (run this code block to view) { display-mode: \"form\" }\n",
        "\n",
        "print(\"\"\"The following columns might contain outliers:\n",
        "\n",
        "  * total_rooms\n",
        "  * total_bedrooms\n",
        "  * population\n",
        "  * households\n",
        "  * possibly, median_income\n",
        "\n",
        "In all of those columns:\n",
        "\n",
        "  * the standard deviation is almost as high as the mean\n",
        "  * the delta between 75% and max is much higher than the\n",
        "      delta between min and 25%.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11a6f727"
      },
      "source": [
        "# Quantify outliers in the identified columns.\n",
        "\n",
        "# Let's look at the distribution of values in the columns that might contain outliers.\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "for column in outlier_columns:\n",
        "  print(f\"\\nStatistics for '{column}':\")\n",
        "  display(training_df[column].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8df7aaa1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the distribution of potential outlier columns using histograms.\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "for column in outlier_columns:\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  training_df[column].hist(bins=50)\n",
        "  plt.title(f'Distribution of {column}')\n",
        "  plt.xlabel(column)\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "779b1905"
      },
      "source": [
        "# Task\n",
        "Handle outliers in the `training_df` by creating copies of the dataframe and applying different outlier handling methods: removal, transformation, and capping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a65853fb"
      },
      "source": [
        "## Create copies of the dataframe\n",
        "\n",
        "### Subtask:\n",
        "Create separate copies of the `training_df` for each outlier handling method we want to explore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c623d30"
      },
      "source": [
        "**Reasoning**:\n",
        "Create three copies of the training_df dataframe as requested in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97c0dca3"
      },
      "source": [
        "df_removed = training_df.copy()\n",
        "df_transformed = training_df.copy()\n",
        "df_capped = training_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2b2aa26"
      },
      "source": [
        "## Handle outliers by removal\n",
        "\n",
        "### Subtask:\n",
        "Remove rows with outliers from one copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b533ce79"
      },
      "source": [
        "**Reasoning**:\n",
        "Remove rows with outliers from the `df_removed` DataFrame based on the calculated IQR bounds for each identified outlier column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15e7a9e6"
      },
      "source": [
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "for column in outlier_columns:\n",
        "  Q1 = df_removed[column].quantile(0.25)\n",
        "  Q3 = df_removed[column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  df_removed = df_removed[(df_removed[column] >= lower_bound) & (df_removed[column] <= upper_bound)]\n",
        "\n",
        "display(df_removed.head())\n",
        "display(df_removed.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c767bc62"
      },
      "source": [
        "## Handle outliers by transformation\n",
        "\n",
        "### Subtask:\n",
        "Apply data transformations (e.g., log transformation) to the outlier columns in another copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23bfdaac"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply log transformation to the identified outlier columns in the `df_transformed` DataFrame to handle outliers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2e785fc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "for column in outlier_columns:\n",
        "  df_transformed[column] = np.log1p(df_transformed[column])\n",
        "\n",
        "display(df_transformed.head())\n",
        "display(df_transformed.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5534d323"
      },
      "source": [
        "## Handle outliers by capping\n",
        "\n",
        "### Subtask:\n",
        "Replace outlier values with capped values (e.g., the 95th percentile) in a third copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db671658"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the 95th percentile for each identified outlier column and cap the values in the `df_capped` DataFrame. Then display the head and descriptive statistics of the modified DataFrame to show the results of the capping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6f4855a"
      },
      "source": [
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "for column in outlier_columns:\n",
        "  percentile_95 = df_capped[column].quantile(0.95)\n",
        "  df_capped[column] = df_capped[column].apply(lambda x: percentile_95 if x > percentile_95 else x)\n",
        "\n",
        "display(df_capped.head())\n",
        "display(df_capped.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2113224"
      },
      "source": [
        "## Compare the results\n",
        "\n",
        "### Subtask:\n",
        "Compare the descriptive statistics or visualizations of the modified dataframes to see the effect of each outlier handling method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f1c20c1"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the descriptive statistics for the outlier columns in each of the modified dataframes and visualize their distributions using histograms to compare the effect of outlier handling methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbf5148"
      },
      "source": [
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "print(\"Descriptive statistics for df_removed:\")\n",
        "display(df_removed[outlier_columns].describe())\n",
        "\n",
        "print(\"\\nDescriptive statistics for df_transformed:\")\n",
        "display(df_transformed[outlier_columns].describe())\n",
        "\n",
        "print(\"\\nDescriptive statistics for df_capped:\")\n",
        "display(df_capped[outlier_columns].describe())\n",
        "\n",
        "# Visualize distributions\n",
        "for column in outlier_columns:\n",
        "  plt.figure(figsize=(18, 5))\n",
        "\n",
        "  plt.subplot(1, 3, 1)\n",
        "  df_removed[column].hist(bins=50)\n",
        "  plt.title(f'Removed Outliers: {column}')\n",
        "  plt.xlabel(column)\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  df_transformed[column].hist(bins=50)\n",
        "  plt.title(f'Transformed Outliers: {column}')\n",
        "  plt.xlabel(f'log1p({column})')\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  df_capped[column].hist(bins=50)\n",
        "  plt.title(f'Capped Outliers: {column}')\n",
        "  plt.xlabel(column)\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7000e9dd"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Three copies of the `training_df` dataframe were successfully created: `df_removed`, `df_transformed`, and `df_capped`.\n",
        "*   Outlier removal using the IQR method on `df_removed` resulted in a reduced number of rows (14406 compared to the original) and lower ranges for the outlier columns.\n",
        "*   Log transformation (`np.log1p`) was successfully applied to the outlier columns in `df_transformed`, significantly changing the scale and distribution of these columns (e.g., 'total\\_rooms' max value changed to approximately 10.5).\n",
        "*   Capping outliers at the 95th percentile in `df_capped` successfully replaced values above this threshold, with the maximum values in the capped columns now equal to their respective 95th percentiles.\n",
        "*   Comparing the results showed that removal reduces dataset size, transformation changes the data scale and reduces skewness, and capping retains all observations while limiting extreme values, creating peaks at the capping points in histograms.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The choice of outlier handling method depends on the specific analysis or modeling goal and the nature of the data. Transformation might be preferred for models sensitive to skewed data, while capping or removal might be suitable when the magnitude of extreme values is the primary concern.\n",
        "*   Further steps could involve evaluating the performance of machine learning models trained on each of the modified dataframes to determine which outlier handling method yields the best results for the specific prediction task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd629985"
      },
      "source": [
        "# Task\n",
        "Apply outlier handling techniques (removal, transformation, capping) and scaling techniques (Min-Max, Standardization, Robust) to separate copies of the `training_df` and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c62f8234"
      },
      "source": [
        "## Create copies of the dataframe\n",
        "\n",
        "### Subtask:\n",
        "Create separate copies of the `training_df` for each outlier handling method and scaling technique we want to explore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7c2b053"
      },
      "source": [
        "**Reasoning**:\n",
        "Create six copies of the training_df dataframe as requested in the instructions for outlier handling and scaling techniques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30e8e1d6"
      },
      "source": [
        "df_removed = training_df.copy()\n",
        "df_transformed = training_df.copy()\n",
        "df_capped = training_df.copy()\n",
        "df_minmax_scaled = training_df.copy()\n",
        "df_standard_scaled = training_df.copy()\n",
        "df_robust_scaled = training_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dc9d9b4"
      },
      "source": [
        "## Handle outliers by min-max scaling\n",
        "\n",
        "### Subtask:\n",
        "Apply Min-Max scaling to the outlier columns in a copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70569747"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply Min-Max scaling to the outlier columns in the `df_minmax_scaled` DataFrame and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3be2291e"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_minmax_scaled[outlier_columns] = scaler.fit_transform(df_minmax_scaled[outlier_columns])\n",
        "\n",
        "display(df_minmax_scaled.head())\n",
        "display(df_minmax_scaled.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d0fc8a5"
      },
      "source": [
        "## Handle outliers by standardization\n",
        "\n",
        "### Subtask:\n",
        "Apply Standardization to the outlier columns in a copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f297f179"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply standardization to the outlier columns in the `df_standard_scaled` DataFrame as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bc9872"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_standard_scaled[outlier_columns] = scaler.fit_transform(df_standard_scaled[outlier_columns])\n",
        "\n",
        "display(df_standard_scaled.head())\n",
        "display(df_standard_scaled.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b462904"
      },
      "source": [
        "## Handle outliers by robust scaling\n",
        "\n",
        "### Subtask:\n",
        "Apply Robust Scaling to the outlier columns in a copy of the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd8d83be"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply Robust Scaling to the identified outlier columns in the df_robust_scaled DataFrame, then display the head and descriptive statistics of the modified DataFrame to show the results of the scaling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b94a0ea7"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "outlier_columns = ['total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "scaler = RobustScaler()\n",
        "df_robust_scaled[outlier_columns] = scaler.fit_transform(df_robust_scaled[outlier_columns])\n",
        "\n",
        "display(df_robust_scaled.head())\n",
        "display(df_robust_scaled.describe())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UzwtQrjFjfv"
      },
      "source": [
        "# ğŸ” Building a Production-Grade PII-Safe RAG Pipeline with Presidio, Qdrant & Custom Recognizers\n",
        "\n",
        "Modern AI systems routinely process sensitive user data â€” including names, emails, phone numbers, government IDs, and financial identifiers. Ensuring that this data is **never leaked**, **never embedded**, and **never exposed** in model outputs is fundamental to responsible AI engineering.\n",
        "\n",
        "This tutorial walks through a complete, practical pipeline for handling sensitive information using:\n",
        "\n",
        "* **Microsoft Presidio** for PII detection and redaction\n",
        "* **Custom-built recognizers** for high-reliability detection of critical identifiers (SSN, credit cards, bank numbers, Aadhaar/PAN, etc.)\n",
        "* **SentenceTransformer embeddings** for vectorization of *sanitized* text\n",
        "* **Qdrant** as the vector database for secure retrieval\n",
        "* **Fernet encryption** for storing original (unredacted) documents safely\n",
        "* **Audit logging** for traceability and compliance support\n",
        "\n",
        "By the end of this walkthrough you will have a fully functioning, end-to-end PII-safe RAG system that:\n",
        "\n",
        "### âœ” Prevents unwanted PII from entering embeddings\n",
        "\n",
        "### âœ” Supports deterministic, high-accuracy entity detection via custom recognizers\n",
        "\n",
        "### âœ” Stores originals in encrypted form for DSARs & audits\n",
        "\n",
        "### âœ” Retrieves only sanitized text into LLM prompts\n",
        "\n",
        "### âœ” Escalates and logs sensitive access operations\n",
        "\n",
        "### âœ” Is fully reproducible and version-stable\n",
        "\n",
        "This mirrors the same architecture patterns used in production systems across finance, healthcare, and enterprise AI deployments â€” but built in a lightweight, reproducible form right inside your Colab environment.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ§­ What Youâ€™ll Learn\n",
        "\n",
        "* How to configure and extend **Presidio** beyond its defaults\n",
        "* Why production systems must **override certain built-in recognizers**\n",
        "* How to safely build a **two-store model** (redacted vectors + encrypted originals)\n",
        "* How to implement **PII-aware retrieval**\n",
        "* How to create a **trusted audit trail** for all access\n",
        "* How to assemble a **safe prompt** for downstream LLMs\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ¯ Why Custom Recognizers Matter\n",
        "\n",
        "While Presidio provides many built-in recognizers, real-world deployments require:\n",
        "\n",
        "* deterministic detection\n",
        "* strong regex patterns\n",
        "* multi-country ID support\n",
        "* strict consistency across versions\n",
        "* reproducibility\n",
        "\n",
        "This tutorial shows you how to **extend Presidio with your own high-assurance recognizers**, ensuring your system doesnâ€™t silently break when built-ins change or fail.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸŒ Who This is For\n",
        "\n",
        "* ML Engineers building **secure RAG pipelines**\n",
        "* Backend engineers integrating LLMs into compliance-sensitive applications\n",
        "* AI security and privacy researchers\n",
        "* Developers working with financial, identity, or healthcare data\n",
        "* Anyone deploying LLMs in production and wanting to â€œdo it rightâ€\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸš€ Ready? Letâ€™s Start Building a Real PII-Safe RAG System.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8WV8zma1Fxo"
      },
      "source": [
        "## 1) Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dTAe5ZOH6_52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 1. Install and load spaCy EN model BEFORE Presidio (critical)\n",
        "# ================================================================\n",
        "!python -m spacy download en_core_web_lg --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA0vY7ef05df",
        "outputId": "98dd9afe-1961-46e2-fc6f-a800b067a536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install presidio-analyzer presidio-anonymizer qdrant-client sentence-transformers cryptography --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG2OnfNSEi9q"
      },
      "source": [
        "## 2) Imports and helper utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17uV9rxs1Q2S",
        "outputId": "425afa40-760a-493f-d562-06f44fdd3db5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dae025ae4324db58280112ebffbda9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c3657c89fb44b97a1c30e2ca67c4196",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c50455f4f7a74eafab1eade3f502fc16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb1276fd96a4e3d8593724b3899b159",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f61c42fe06b4631bfab22a44b994676",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247e6e21fc9c45f79780ce3e3acf2737",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "905be43380274db987e9edc2a2ff868b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83737d8795014670990d554430e9fc79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e1817e5122e412fa318f30567a84caf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f903d9f5a4764939abe113a585705588",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5274b39f14fb4b328ee6f998e2eb8ec0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. Qdrant collection: docs_redacted\n",
            "Working directory: /content/pii_rag_demo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4225155516.py:65: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant.recreate_collection(\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# 1. Standard imports\n",
        "# ----------------------------\n",
        "import os, json, time, uuid\n",
        "from pathlib import Path\n",
        "\n",
        "# Presidio\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Qdrant (local mode)\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance\n",
        "\n",
        "# Encryption\n",
        "from cryptography.fernet import Fernet\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Colab-friendly directories\n",
        "# ----------------------------\n",
        "DATA_DIR = Path(\"/content/pii_rag_demo\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ORIGINALS_DIR = DATA_DIR / \"originals\"\n",
        "ORIGINALS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "ENCRYPTED_DIR = DATA_DIR / \"encrypted_originals\"\n",
        "ENCRYPTED_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "AUDIT_LOG_PATH = DATA_DIR / \"audit_log.ndjson\"\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Initialize Presidio engines\n",
        "# ----------------------------\n",
        "analyzer = AnalyzerEngine()      # uses spaCy pipeline you installed\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Embedding model\n",
        "# ----------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Qdrant local DB (disk persistence in Colab)\n",
        "# ----------------------------\n",
        "qdrant_path = DATA_DIR / \"qdrant_db\"\n",
        "qdrant = QdrantClient(path=str(qdrant_path))\n",
        "\n",
        "COLLECTION_NAME = \"docs_redacted\"\n",
        "VECTOR_SIZE = embed_model.get_sentence_embedding_dimension()\n",
        "\n",
        "# Create collection if not exists\n",
        "collections = qdrant.get_collections().collections\n",
        "existing = [c.name for c in collections]\n",
        "\n",
        "if COLLECTION_NAME not in existing:\n",
        "    qdrant.recreate_collection(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE),\n",
        "    )\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Encryption key handling\n",
        "# ----------------------------\n",
        "KEY_PATH = DATA_DIR / \"fernet.key\"\n",
        "\n",
        "if not KEY_PATH.exists():\n",
        "    key = Fernet.generate_key()\n",
        "    KEY_PATH.write_bytes(key)\n",
        "else:\n",
        "    key = KEY_PATH.read_bytes()\n",
        "\n",
        "fernet = Fernet(key)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Audit log helper\n",
        "# ----------------------------\n",
        "def audit_log(event: dict):\n",
        "    entry = {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"ts\": time.time(),\n",
        "        **event\n",
        "    }\n",
        "    with open(AUDIT_LOG_PATH, \"a\") as f:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "\n",
        "print(\"Setup complete. Qdrant collection:\", COLLECTION_NAME)\n",
        "print(\"Working directory:\", DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN1l5IHPErGM"
      },
      "source": [
        "## 3) Sample documents (3 docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txGx-dKr2ihW",
        "outputId": "cf527d7b-ab05-4391-b2ac-eb354675706d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved originals to /content/pii_rag_demo/originals\n"
          ]
        }
      ],
      "source": [
        "docs = {\n",
        "\"doc1\": {\n",
        "\"title\": \"Meeting notes\",\n",
        "\"text\": \"We met with Acme Corp. Agenda: roadmap, Q4 planning. Attendees: Alice, Bob.\"\n",
        "},\n",
        "\"doc2\": {\n",
        "\"title\": \"Patient record\",\n",
        "\"text\": \"Patient John Doe, born 1990-01-01, email john.doe@example.com, SSN 123-45-6789, phone +1 555-123-4567. Notes: allergic to penicillin.\"\n",
        "},\n",
        "\"doc3\": {\n",
        "\"title\": \"Engineer bio\",\n",
        "\"text\": \"Dev: Amar Singh. Email: amar@example.org. Likes football and ML.\"\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "# Save originals (plaintext) and audit\n",
        "for doc_id, doc in docs.items():\n",
        "  p = ORIGINALS_DIR / f\"{doc_id}.txt\"\n",
        "  p.write_text(doc[\"text\"], encoding=\"utf-8\")\n",
        "  audit_log({\"event\":\"ingest_plain_save\",\"doc_id\":doc_id, \"path\":str(p)})\n",
        "\n",
        "\n",
        "print(\"Saved originals to\", ORIGINALS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkNxLh2I-xyI",
        "outputId": "ab1d994e-e279-4c31-cb09-105d2134a23a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total recognizers: 16\n",
            "--------------------------------------\n",
            "CreditCardRecognizer: ['CREDIT_CARD']\n",
            "UsBankRecognizer: ['US_BANK_NUMBER']\n",
            "UsLicenseRecognizer: ['US_DRIVER_LICENSE']\n",
            "UsItinRecognizer: ['US_ITIN']\n",
            "UsPassportRecognizer: ['US_PASSPORT']\n",
            "UsSsnRecognizer: ['US_SSN']\n",
            "NhsRecognizer: ['UK_NHS']\n",
            "CryptoRecognizer: ['CRYPTO']\n",
            "DateRecognizer: ['DATE_TIME']\n",
            "EmailRecognizer: ['EMAIL_ADDRESS']\n",
            "IbanRecognizer: ['IBAN_CODE']\n",
            "IpRecognizer: ['IP_ADDRESS']\n",
            "MedicalLicenseRecognizer: ['MEDICAL_LICENSE']\n",
            "PhoneRecognizer: ['PHONE_NUMBER']\n",
            "UrlRecognizer: ['URL']\n",
            "SpacyRecognizer: ['DATE_TIME', 'NRP', 'LOCATION', 'PERSON', 'ORGANIZATION']\n"
          ]
        }
      ],
      "source": [
        "from presidio_analyzer import RecognizerRegistry\n",
        "\n",
        "registry = RecognizerRegistry()\n",
        "registry.load_predefined_recognizers()\n",
        "all_recognizers = registry.recognizers   # <-- internal list, safe to inspect\n",
        "\n",
        "print(\"Total recognizers:\", len(all_recognizers))\n",
        "print(\"--------------------------------------\")\n",
        "for r in all_recognizers:\n",
        "    print(f\"{r.__class__.__name__}: {r.supported_entities}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFW6xQ26Bxji",
        "outputId": "085a95c4-ea01-4878-8409-6ede31fdea47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added custom SSN recognizer.\n"
          ]
        }
      ],
      "source": [
        "from presidio_analyzer import Pattern, PatternRecognizer\n",
        "\n",
        "ssn_pattern = Pattern(\n",
        "    name=\"ssn_pattern\",\n",
        "    regex=r\"\\b(?!(000|666|9))\\d{3}[- ]?(?!00)\\d{2}[- ]?(?!0000)\\d{4}\\b\",\n",
        "    score=0.8,\n",
        ")\n",
        "\n",
        "custom_ssn_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"SSN\",\n",
        "    patterns=[ssn_pattern],\n",
        "    supported_language=\"en\"\n",
        ")\n",
        "\n",
        "analyzer.registry.add_recognizer(custom_ssn_recognizer)\n",
        "\n",
        "print(\"Added custom SSN recognizer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy6axg81Dxjt",
        "outputId": "1e25d6eb-dabe-4fd5-9880-f70a33dc1c83"
      },
      "outputs": [],
      "source": [
        "text = \"SSN 123-45-6789 belongs to John Doe\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1zehtwcZDki_"
      },
      "outputs": [],
      "source": [
        "res = analyzer.analyze(\n",
        "    text=text,\n",
        "    entities=[\"SSN\"],   # <-- custom recognizer\n",
        "    language=\"en\"\n",
        ")\n",
        "\n",
        "redacted = anonymizer.anonymize(\n",
        "    text=text,\n",
        "    analyzer_results=res,\n",
        "    operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\":\"[REDACTED]\"})}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[type: SSN, start: 4, end: 15, score: 0.8]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(analyzer.analyze(text, entities=[\"SSN\"], language=\"en\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3j7VdukE0PW"
      },
      "source": [
        "## 4) PII detection, redaction, sensitivity scoring, encryption of original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8iIpN-D3Om0",
        "outputId": "06d042ee-8ec6-4528-8602-d652544c1ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingest & index complete. Qdrant collection has docs.\n"
          ]
        }
      ],
      "source": [
        "ENTITIES = [\n",
        "    \"PERSON\",\n",
        "    \"PHONE_NUMBER\",\n",
        "    \"EMAIL_ADDRESS\",\n",
        "    \"SSN\",\n",
        "    \"DATE_TIME\",\n",
        "    \"LOCATION\",\n",
        "]\n",
        "\n",
        "from qdrant_client.models import PointStruct\n",
        "\n",
        "# Simple sensitivity scoring\n",
        "WEIGHTS = {\n",
        "    \"US_SSN\": 10,\n",
        "    \"EMAIL_ADDRESS\": 3,\n",
        "    \"PHONE_NUMBER\": 3,\n",
        "    \"PERSON\": 2,\n",
        "    \"LOCATION\": 2,\n",
        "    \"DATE_TIME\": 1,\n",
        "}\n",
        "\n",
        "def sensitivity_score(results):\n",
        "    score = 0\n",
        "    for r in results:\n",
        "        score += WEIGHTS.get(r.entity_type, 1)\n",
        "    return score\n",
        "\n",
        "\n",
        "# Redaction operator: replace with [REDACTED_<TYPE>]\n",
        "\n",
        "\n",
        "def make_ops(results):\n",
        "    # We will supply per-entity operators but the anonymizer can use DEFAULT as well\n",
        "    return {\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"})}\n",
        "\n",
        "\n",
        "# Process and index each doc\n",
        "for doc_id, doc in docs.items():\n",
        "    text = doc[\"text\"]\n",
        "    results = analyzer.analyze(text=text, entities=ENTITIES, language=\"en\")\n",
        "    score = sensitivity_score(results)\n",
        "    ops = make_ops(results)\n",
        "    anonymized = anonymizer.anonymize(text=text, analyzer_results=results, operators=ops)\n",
        "    redacted_text = anonymized.text\n",
        "\n",
        "    # Save redacted text to a file (for auditing and to index)\n",
        "    redacted_path = DATA_DIR / f\"{doc_id}_redacted.txt\"\n",
        "    redacted_path.write_text(redacted_text, encoding=\"utf-8\")\n",
        "\n",
        "    # Encrypt original and save encrypted blob\n",
        "    orig_path = ORIGINALS_DIR / f\"{doc_id}.txt\"\n",
        "    data = orig_path.read_bytes()\n",
        "    token = fernet.encrypt(data)\n",
        "    enc_path = ENCRYPTED_DIR / f\"{doc_id}.enc\"\n",
        "    enc_path.write_bytes(token)\n",
        "\n",
        "    # Create embedding for redacted text\n",
        "    embedding = embed_model.encode(redacted_text).tolist()\n",
        "\n",
        "    # Upsert into Qdrant\n",
        "    metadata = {\n",
        "        \"doc_id\": doc_id,\n",
        "        \"title\": doc[\"title\"],\n",
        "        \"redacted_path\": str(redacted_path),\n",
        "        \"encrypted_path\": str(enc_path),\n",
        "        \"sensitivity_score\": score,\n",
        "        \"detected_entities\": [\n",
        "            {\"type\": r.entity_type, \"start\": r.start, \"end\": r.end, \"score\": r.score}\n",
        "            for r in results\n",
        "        ],\n",
        "    }\n",
        "    qdrant.upsert(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        points=[\n",
        "            PointStruct(id=str(uuid.uuid5(uuid.NAMESPACE_DNS, doc_id)), vector=embedding, payload=metadata)\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    audit_log(\n",
        "        {\n",
        "            \"event\": \"ingest_indexed\",\n",
        "            \"doc_id\": doc_id,\n",
        "            \"redacted_path\": str(redacted_path),\n",
        "            \"encrypted_path\": str(enc_path),\n",
        "            \"sensitivity_score\": score,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Ingest & index complete. Qdrant collection has docs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ITgS4HZE5hb"
      },
      "source": [
        "## 5) Retrieval demo + guardrail escalation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8HrYc9N3n_v",
        "outputId": "ee876dfd-83d3-4314-f155-501cc87458d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query 1: 'roadmap' -> expects doc1\n",
            "{'action': 'escalate', 'doc': {'id': 'fbe4ef3e-9402-5135-99fb-e5bf7ddcfa7a', 'score': 0.09000228879242692, 'payload': {'doc_id': 'doc2', 'title': 'Patient record', 'redacted_path': '/content/pii_rag_demo/doc2_redacted.txt', 'encrypted_path': '/content/pii_rag_demo/encrypted_originals/doc2.enc', 'sensitivity_score': 10, 'detected_entities': [{'type': 'EMAIL_ADDRESS', 'start': 41, 'end': 61, 'score': 1.0}, {'type': 'PERSON', 'start': 8, 'end': 16, 'score': 0.85}, {'type': 'DATE_TIME', 'start': 23, 'end': 33, 'score': 0.85}, {'type': 'SSN', 'start': 67, 'end': 78, 'score': 0.8}, {'type': 'PHONE_NUMBER', 'start': 89, 'end': 101, 'score': 0.75}]}}}\n",
            "\n",
            "Query 2: 'patient John' -> should trigger escalation due to SSN/email\n",
            "{'action': 'escalate', 'doc': {'id': '460ae2af-2a4b-58d5-b3e0-a142023d83bb', 'score': 0.012802616797205825, 'payload': {'doc_id': 'doc1', 'title': 'Meeting notes', 'redacted_path': '/content/pii_rag_demo/doc1_redacted.txt', 'encrypted_path': '/content/pii_rag_demo/encrypted_originals/doc1.enc', 'sensitivity_score': 6, 'detected_entities': [{'type': 'LOCATION', 'start': 40, 'end': 42, 'score': 0.85}, {'type': 'PERSON', 'start': 64, 'end': 69, 'score': 0.85}, {'type': 'PERSON', 'start': 71, 'end': 74, 'score': 0.85}]}}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3566079056.py:6: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  resp = qdrant.search(collection_name=COLLECTION_NAME, query_vector=q_vec, limit=top_k)\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client.http import models as rest_models\n",
        "\n",
        "\n",
        "def retrieve(query, top_k=3, score_threshold=8):\n",
        "  q_vec = embed_model.encode(query).tolist()\n",
        "  resp = qdrant.search(collection_name=COLLECTION_NAME, query_vector=q_vec, limit=top_k)\n",
        "  hits = []\n",
        "  for p in resp:\n",
        "    payload = p.payload\n",
        "    hits.append({\n",
        "    \"id\": p.id,\n",
        "    \"score\": p.score,\n",
        "    \"payload\": payload\n",
        "    })\n",
        "# Check sensitivity\n",
        "  for h in hits:\n",
        "    if h[\"payload\"].get(\"sensitivity_score\", 0) >= score_threshold:\n",
        "      audit_log({\"event\":\"retrieval_escalate\",\"query\":query,\"doc_id\":h[\"id\"],\"sensitivity_score\":h[\"payload\"][\"sensitivity_score\"]})\n",
        "  return {\"action\":\"escalate\",\"doc\":h}\n",
        "# else assemble context\n",
        "  context = \"\\n\\n\".join([ Path(h[\"payload\"][\"redacted_path\"]).read_text(encoding=\"utf-8\") for h in hits ])\n",
        "  audit_log({\"event\":\"retrieval_ok\",\"query\":query,\"doc_ids\":[h[\"id\"] for h in hits]})\n",
        "  return {\"action\":\"ok\",\"context\":context,\"hits\":hits}\n",
        "\n",
        "\n",
        "# Run two queries: one innocuous, one that triggers escalate\n",
        "print(\"Query 1: 'roadmap' -> expects doc1\")\n",
        "print(retrieve(\"roadmap\"))\n",
        "\n",
        "\n",
        "print(\"\\nQuery 2: 'patient John' -> should trigger escalation due to SSN/email\")\n",
        "print(retrieve(\"patient John\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA_D9QCZE_t4"
      },
      "source": [
        "## 6) How to satisfy a DSAR / delete request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9bBAxyz4A1i"
      },
      "outputs": [],
      "source": [
        "# Example: delete doc2 from both Qdrant and encrypted store\n",
        "def delete_doc(doc_id):\n",
        "# delete from qdrant\n",
        "  qdrant.delete(collection_name=COLLECTION_NAME, points=[doc_id])\n",
        "  # delete encrypted file\n",
        "  enc_path = ENCRYPTED_DIR / f\"{doc_id}.enc\"\n",
        "  if enc_path.exists():\n",
        "    enc_path.unlink()\n",
        "# append audit\n",
        "  audit_log({\"event\":\"dsar_delete\",\"doc_id\":doc_id})\n",
        "\n",
        "\n",
        "# Demonstrate\n",
        "print(\"Before deletion, search for 'patient'\")\n",
        "print(retrieve(\"patient\"))\n",
        "\n",
        "\n",
        "print(\"Deleting doc2...\")\n",
        "delete_doc(\"doc2\")\n",
        "\n",
        "\n",
        "print(\"After deletion, search for 'patient' -> should not return doc2\")\n",
        "print(retrieve(\"patient\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Nov 12 14:30 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6YgWN5WFDn7"
      },
      "source": [
        "## 7) Notes, security & production considerations\n",
        "\n",
        "- Key Management: In production, do not store Fernet keys locally. Use a KMS (AWS KMS, GCP KMS, Azure Key Vault) and rotate keys. Use MultiFernet for rotation.\n",
        "\n",
        "- RBAC: Protect Qdrant endpoints and encrypted storage with access controls.\n",
        "\n",
        "- PII Detection Coverage: Presidio covers many entities; extend with custom recognizers for domain-specific PII.\n",
        "\n",
        "- Audit Durability: Use append-only logging to an immutable store (Cloud Storage with WORM settings, or an append-only DB).\n",
        "\n",
        "- Human-in-the-loop UI: For escalations, integrate a simple approve/reject workflow (e.g., Streamlit) to inspect encrypted originals (after appropriate auth) and approve redacted excerpts."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
